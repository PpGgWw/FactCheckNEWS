"""
ìº¡ìŠ¤í†¤ í”„ë¡œì íŠ¸ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼ ğŸ“
Flask ì›¹ ì„œë²„ì™€ ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
(í¬ë¡¤ëŸ¬ ê¸°ëŠ¥, AI ë¶„ì„ API ì‹œë®¬ë ˆì´ì…˜ ê¸°ëŠ¥ ì¶”ê°€)
"""
import json
import re
import html
import time
import traceback
import random # ğŸ² ë¬´ì‘ìœ„ ì ìˆ˜ ìƒì„±ì„ ìœ„í•´ ì¶”ê°€
from typing import List, Dict, Tuple, Optional, Any
from flask import Flask, render_template, request, redirect, url_for, Response, jsonify

# ğŸ› ï¸ ìì²´ ì œì‘ ëª¨ë“ˆ ì„í¬íŠ¸
from modules import highlighter # í˜„ì¬ëŠ” ë§ì´ ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ, í…ìŠ¤íŠ¸ í•˜ì´ë¼ì´íŠ¸ ê¸°ëŠ¥
from modules import crawler # ğŸ“° ë‰´ìŠ¤ ì›¹ í¬ë¡¤ë§ ë‹´ë‹¹
from modules import analyzer_api_simulator # ğŸ¤– AI ë¶„ì„ API í˜¸ì¶œ ì‹œë®¬ë ˆì´í„°

# --- ğŸŒ ìƒìˆ˜ ì •ì˜ ---
DEFAULT_USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'
NAVER_NEWS_DOMAIN = "news.naver.com" # ë„¤ì´ë²„ ë‰´ìŠ¤ ë„ë©”ì¸

app = Flask(__name__)

# --- âœ¨ Helper Functions (ë³´ì¡° í•¨ìˆ˜) ---
def clean_extracted_text(text: Optional[str], remove_trailing_number: bool = False) -> Optional[str]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ ìœ ì‚¬ ì„œì‹ì´ë‚˜ ì•ë’¤ ê³µë°±, íŠ¹ì • íŒ¨í„´ì„ ì œê±°í•©ë‹ˆë‹¤.
    Args:
        text (Optional[str]): ì •ë¦¬í•  í…ìŠ¤íŠ¸.
        remove_trailing_number (bool): í…ìŠ¤íŠ¸ ëì˜ 'ìˆ«ì.' íŒ¨í„´ ì œê±° ì—¬ë¶€.
    Returns:
        Optional[str]: ì •ë¦¬ëœ í…ìŠ¤íŠ¸.
    """
    if not text: return None
    cleaned = text.strip()
    # ë§ˆí¬ë‹¤ìš´ ë³¼ë“œ/ì´íƒ¤ë¦­ ë“± ì œê±°
    cleaned = re.sub(r'\*\*(.*?)\*\*', r'\1', cleaned) # **bold** -> bold
    cleaned = re.sub(r'__(.*?)__', r'\1', cleaned) # __underline__ -> underline
    cleaned = re.sub(r'\*(.*?)\*', r'\1', cleaned)   # *italic* -> italic
    cleaned = re.sub(r'_(.*?)_', r'\1', cleaned)   # _italic_ -> italic
    # ëª©ë¡ í‘œì‹œì ì œê±°
    cleaned = re.sub(r'^\s*[-*+]\s*', '', cleaned) # ë¬¸ì¥ ì‹œì‘ì˜ -, *, + ì œê±°
    # ì•ë’¤ ë”°ì˜´í‘œ ì œê±°
    if len(cleaned) >= 2 and ((cleaned.startswith('"') and cleaned.endswith('"')) or \
                               (cleaned.startswith("'") and cleaned.endswith("'"))):
        cleaned = cleaned[1:-1]
    # ì—¬ëŸ¬ ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    # ëì— ì˜¤ëŠ” 'ìˆ«ì.' íŒ¨í„´ ì œê±° (ì˜ˆ: "ë¬¸ì¥ì…ë‹ˆë‹¤. 1.")
    if remove_trailing_number:
        cleaned = re.sub(r'\s*\d+\.\s*$', '', cleaned).strip()
    return cleaned if cleaned else None

def parse_llama_analysis(raw_text: str) -> Tuple[List[Dict[str, Any]], str, Optional[str], Optional[str]]:
    """
    âš ï¸ ë ˆê±°ì‹œ Llama ë¶„ì„ íŒŒì‹± í•¨ìˆ˜ì…ë‹ˆë‹¤. (í˜„ì¬ ì‹œë®¬ë ˆì´ì…˜/ë™ì‘ ì—†ìŒ)
    ì›ë˜ëŠ” Llama ëª¨ë¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í–ˆì§€ë§Œ, í˜„ì¬ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    Args:
        raw_text (str): Llama ëª¨ë¸ì˜ ì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸.
    Returns:
        Tuple: ë¹ˆ ë¦¬ìŠ¤íŠ¸, HTML í˜•ì‹ì˜ ì›ë³¸ í…ìŠ¤íŠ¸, "ë¶„ì„ ì •ë³´ ì—†ìŒ", "ì •ë³´ ì—†ìŒ".
    """
    structured_analysis: List[Dict[str, Any]] = []
    formatted_html = f'<p class="analysis-raw">{html.escape(raw_text)}</p>' # ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ HTMLë¡œ í‘œì‹œ
    print(f"[Parsing] âš ï¸ Legacy Llama parsing (simulated/no-op).")
    return [], formatted_html, "ë¶„ì„ ì •ë³´ ì—†ìŒ", "ì •ë³´ ì—†ìŒ"


# --- ğŸ“ ë¼ìš°íŠ¸ ì •ì˜ ---
@app.route('/')
def index():
    """ ğŸ  ë©”ì¸ í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤. """
    return render_template('index.html')

@app.route('/process', methods=['POST'])
def process_url():
    """
    ì‚¬ìš©ìë¡œë¶€í„° ë‰´ìŠ¤ URL ë˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì²˜ë¦¬ í˜ì´ì§€ë¡œ ë„˜ê¹ë‹ˆë‹¤.
    ë„¤ì´ë²„ ë‰´ìŠ¤ URLì¸ ê²½ìš° í¬ë¡¤ë§ì„ ì‹œë„í•˜ê³ , ê·¸ ì™¸ì—ëŠ” ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    if request.method == 'POST':
        news_input = request.form.get('news_text', '').strip() # ğŸ“ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê°’

        if not news_input:
            print(f"[Routing] â¡ï¸ ì•„ë¬´ê²ƒë„ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.")
            return redirect(url_for('index'))

        news_text_to_process = "" # ìµœì¢…ì ìœ¼ë¡œ ë¶„ì„ë  í…ìŠ¤íŠ¸
        article_title_to_process = "ì…ë ¥ëœ ë‚´ìš©" # ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©ë  ê¸°ì‚¬ ì œëª©

        # URLì¸ì§€ í…ìŠ¤íŠ¸ì¸ì§€ íŒë³„
        is_url = news_input.startswith('http://') or news_input.startswith('https://')

        if is_url:
            if NAVER_NEWS_DOMAIN in news_input: # ë„¤ì´ë²„ ë‰´ìŠ¤ URLì¸ ê²½ìš°
                print(f"[Routing] ğŸ”— ë„¤ì´ë²„ ë‰´ìŠ¤ URL ê°ì§€. í¬ë¡¤ë§ ì‹œë„: {news_input}")
                crawled_data = crawler.extract_news_data(news_input) # ğŸ“° í¬ë¡¤ëŸ¬ í˜¸ì¶œ

                if "error" in crawled_data or not crawled_data.get("ë³¸ë¬¸"):
                    error_msg = crawled_data.get("error", "ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.")
                    print(f"[Routing] ğŸ› í¬ë¡¤ë§ ì˜¤ë¥˜ ë˜ëŠ” ë‚´ìš© ì—†ìŒ: {error_msg}")
                    news_text_to_process = f"URL í¬ë¡¤ë§ ì‹¤íŒ¨: {html.escape(error_msg)}\nì…ë ¥ëœ URL: {html.escape(news_input)}"
                    article_title_to_process = crawled_data.get("ì œëª©") or "í¬ë¡¤ë§ ì˜¤ë¥˜"
                else:
                    news_text_to_process = crawled_data.get("ë³¸ë¬¸", "")
                    article_title_to_process = crawled_data.get("ì œëª©", "ì œëª© ì—†ìŒ")
                    if not news_text_to_process.strip(): # ë³¸ë¬¸ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°
                         news_text_to_process = "ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°€ì ¸ì™”ìœ¼ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
            else: # ë„¤ì´ë²„ ë‰´ìŠ¤ê°€ ì•„ë‹Œ URL
                print(f"[Routing] ğŸ”— ì§€ì›í•˜ì§€ ì•ŠëŠ” URL ê°ì§€: {news_input}")
                news_text_to_process = f"ì§€ì›ë˜ì§€ ì•ŠëŠ” URLì…ë‹ˆë‹¤: {html.escape(news_input)}\në„¤ì´ë²„ ë‰´ìŠ¤ URLì„ ì…ë ¥í•˜ê±°ë‚˜ ë‚´ìš©ì„ ì§ì ‘ ì…ë ¥í•´ì£¼ì„¸ìš”."
                article_title_to_process = "ì§€ì›ë˜ì§€ ì•ŠëŠ” URL"
        else: # ì¼ë°˜ í…ìŠ¤íŠ¸ ì…ë ¥
            print(f"[Routing] âœï¸ í…ìŠ¤íŠ¸ ì…ë ¥ ê°ì§€.")
            news_text_to_process = news_input

        # ë‚´ìš© ê¸¸ì´ ê²€ì¦ (ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
        is_error_message_generated = "í¬ë¡¤ë§ ì‹¤íŒ¨" in news_text_to_process or \
                                     "ì§€ì›ë˜ì§€ ì•ŠëŠ” URL" in news_text_to_process or \
                                     "ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤" in news_text_to_process

        if len(news_text_to_process.strip()) < 10 and not is_error_message_generated:
            print(f"[Routing] ğŸ“ ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ê¸¸ì´: {len(news_text_to_process.strip())}).")
            original_title_if_any = article_title_to_process if article_title_to_process != "ì…ë ¥ëœ ë‚´ìš©" else "ë‚´ìš© ë¶„ì„"
            news_text_to_process = "ì…ë ¥ëœ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 10ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”."
            article_title_to_process = original_title_if_any


        print(f"[Routing] âš™ï¸ ì²˜ë¦¬ í˜ì´ì§€ ë Œë”ë§. ì œëª©: '{article_title_to_process[:50]}...', í…ìŠ¤íŠ¸ ê¸¸ì´: {len(news_text_to_process)}")
        return render_template('processing.html',
                               news_text_data=news_text_to_process,
                               article_title_data=article_title_to_process)
    else: # POST ìš”ì²­ì´ ì•„ë‹ˆë©´ ë©”ì¸ìœ¼ë¡œ
        return redirect(url_for('index'))

@app.route('/get_analysis_stream')
def get_analysis_stream():
    """
    í´ë¼ì´ì–¸íŠ¸ì—ê²Œ Server-Sent Events (SSE)ë¥¼ í†µí•´ ë¶„ì„ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
    AI ë¶„ì„ API ì‹œë®¬ë ˆì´í„°ë¥¼ í˜¸ì¶œí•˜ê³  ê·¸ ê²°ê³¼ë¥¼ ë‹¨ê³„ë³„ ë˜ëŠ” ìµœì¢…ì ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    news_text_from_client = request.args.get('news_text_data') # í´ë¼ì´ì–¸íŠ¸ê°€ ë³´ë‚¸ ë‰´ìŠ¤ ë³¸ë¬¸
    article_title_from_client = request.args.get('article_title_data', 'ì…ë ¥ëœ ë‚´ìš©') # í´ë¼ì´ì–¸íŠ¸ê°€ ë³´ë‚¸ ê¸°ì‚¬ ì œëª©

    if not news_text_from_client:
        # ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ì´ë²¤íŠ¸ ì „ì†¡
        def error_stream():
            yield f"event: error\ndata: {json.dumps({'message': 'ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.'})}\n\n"
        return Response(error_stream(), mimetype='text/event-stream', status=400)

    print(f"[SSE] ğŸš€ 'analysis' ìŠ¤íŠ¸ë¦¼ ì‹œì‘. ì œëª©: '{article_title_from_client[:50]}...', í…ìŠ¤íŠ¸ ê¸¸ì´: {len(news_text_from_client)}.")

    def generate_analysis_data(current_title: str, current_content: str):
        """ë¶„ì„ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  SSE ì´ë²¤íŠ¸ë¡œ yieldí•˜ëŠ” ì œë„ˆë ˆì´í„° í•¨ìˆ˜ì…ë‹ˆë‹¤."""
        actual_ai_result = None # ğŸ¤– ì‹¤ì œ AI ë¶„ì„ ê²°ê³¼ (ë˜ëŠ” ì‹œë®¬ë ˆì´ì…˜ëœ ê²°ê³¼)
        sse_error_message = None # SSE ìŠ¤íŠ¸ë¦¼ ë‚´ì—ì„œ ì‚¬ìš©í•  ì˜¤ë¥˜ ë©”ì‹œì§€
        score = 0 # ğŸ“Š ì‹ ë¢°ë„ ì ìˆ˜ (ëœë¤ ìƒì„±)

        # ì…ë ¥ ìì²´ì— ì˜¤ë¥˜ê°€ ìˆëŠ”ì§€ í™•ì¸
        is_input_error = "í¬ë¡¤ë§ ì‹¤íŒ¨:" in current_content or \
                         "ì§€ì›ë˜ì§€ ì•ŠëŠ” URLì…ë‹ˆë‹¤:" in current_content or \
                         "ì…ë ¥ëœ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤." == current_content.strip() or \
                         "ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°€ì ¸ì™”ìœ¼ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤." == current_content.strip()

        try:
            yield f"event: status\ndata: {json.dumps({'step': 'ì…ë ¥ëœ ë‚´ìš©ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...'})}\n\n" # â³ ìƒíƒœ ì—…ë°ì´íŠ¸
            time.sleep(0.2)

            if is_input_error: # ì…ë ¥ ì˜¤ë¥˜ê°€ ìˆë‹¤ë©´ AI ë¶„ì„ ê±´ë„ˆë›°ê¸°
                yield f"event: status\ndata: {json.dumps({'step': 'ì…ë ¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. AI ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.'})}\n\n"
                sse_error_message = current_content # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                actual_ai_result = { # ì˜¤ë¥˜ ì‹œì—ë„ AI ê²°ê³¼ êµ¬ì¡°ëŠ” ìœ ì§€
                    "ì§„ìœ„": "íŒë‹¨ ë¶ˆê°€ (ì…ë ¥ ì˜¤ë¥˜)",
                    "ê·¼ê±°": current_content,
                    "ë¶„ì„": "ì…ë ¥ëœ ë‰´ìŠ¤ ë‚´ìš©ì— ë¬¸ì œê°€ ìˆì–´ AI ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
            else: # ì •ìƒ ì…ë ¥ì´ë©´ AI ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜
                yield f"event: status\ndata: {json.dumps({'step': 'AI ë¶„ì„ API í˜¸ì¶œ ì¤‘... ğŸ¤–'})}\n\n"
                time.sleep(0.1)

                # ğŸ¤– AI ë¶„ì„ API ì‹œë®¬ë ˆì´í„° í˜¸ì¶œ
                actual_ai_result = analyzer_api_simulator.call_fake_analysis_api(current_content, current_title)
                print(f"[SSE] âœ… AI ë¶„ì„ API ê²°ê³¼ ìˆ˜ì‹ : {str(actual_ai_result)[:100]}...")


                yield f"event: status\ndata: {json.dumps({'step': 'AI ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ ì •ë¦¬ ì¤‘... âœ¨'})}\n\n"
                time.sleep(0.1)

                if actual_ai_result: # AI ê²°ê³¼ì— ë”°ë¼ ì ìˆ˜ ëœë¤ ìƒì„±
                    veracity = actual_ai_result.get("ì§„ìœ„", "").lower()
                    if "ì§„ì§œ ë‰´ìŠ¤" in veracity: score = random.randint(70, 95)
                    elif "ê°€ì§œì¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë‰´ìŠ¤" in veracity: score = random.randint(20, 40)
                    elif "ê°€ì§œì¼ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ë‰´ìŠ¤" in veracity: score = random.randint(40, 60)
                    elif "ê°€ì§œ ë‰´ìŠ¤" in veracity: score = random.randint(0, 20)
                    else: score = random.randint(30, 50) # íŒë‹¨ ë¶ˆê°€, ì˜¤ë¥˜ ë“±
                
                sse_error_message = "AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
                if "ì˜¤ë¥˜" in actual_ai_result.get("ì§„ìœ„", ""): # AI ê²°ê³¼ ìì²´ì— ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´
                    sse_error_message = actual_ai_result.get("ê·¼ê±°", "AI ë¶„ì„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


            # ğŸ’¡ í˜„ì¬ëŠ” highlighter ëª¨ë“ˆì„ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ì›ë³¸ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
            # í•˜ì´ë¼ì´íŒ… ë¡œì§ì€ í´ë¼ì´ì–¸íŠ¸(JavaScript) ë˜ëŠ” í•„ìš”ì‹œ ì—¬ê¸°ì„œ ì¶”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
            article_content_highlighted = html.escape(current_content).replace('\n', '<br>')

            final_data = { # ğŸ“¦ í´ë¼ì´ì–¸íŠ¸ì— ìµœì¢…ì ìœ¼ë¡œ ì „ë‹¬í•  ë°ì´í„°
                'score': score,
                'article_title': html.escape(current_title),
                'article_content_original': current_content, # ì›ë³¸ í…ìŠ¤íŠ¸ (ì´ìŠ¤ì¼€ì´í”„ ì•ˆë¨)
                'article_content_highlighted': article_content_highlighted, # HTMLë¡œ í‘œì‹œë  ë³¸ë¬¸
                'simulated_ai_result': actual_ai_result, # AI ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
                'error_message': sse_error_message # ì˜¤ë¥˜ ë©”ì‹œì§€ (ìˆì„ ê²½ìš°)
            }

            print(f"[SSE] ğŸ“Š ìµœì¢… ë°ì´í„° ì¤€ë¹„: ì œëª©='{current_title[:30]}...', ì ìˆ˜={score}, AI ì§„ìœ„='{actual_ai_result.get('ì§„ìœ„', 'N/A') if actual_ai_result else 'N/A'}'")
            yield f"event: final_data\ndata: {json.dumps(final_data)}\n\n" # ğŸ ìµœì¢… ë°ì´í„° ì „ì†¡
            print("[SSE] âœ… ìµœì¢… ë°ì´í„° í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡ ì™„ë£Œ.")

        except Exception as main_e: # ğŸ› ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ì²˜ë¦¬
            print(f"[SSE] ğŸ’¥ generate_analysis_data ë‚´ì—ì„œ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {main_e}")
            print(traceback.format_exc()) # ìƒì„¸ ì˜¤ë¥˜ ë¡œê·¸ ì¶œë ¥
            error_payload = {
                'message': f'ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(main_e)}',
                'simulated_ai_result': { # AI ê²°ê³¼ ë¶€ë¶„ë„ ì˜¤ë¥˜ë¡œ ì±„ì›€
                    "ì§„ìœ„": "ì˜¤ë¥˜", "ê·¼ê±°": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ ë°œìƒ", "ë¶„ì„": str(main_e)
                }
            }
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n" # ì˜¤ë¥˜ ì´ë²¤íŠ¸ ì „ì†¡


    # ğŸ“¨ SSE ì‘ë‹µ ìƒì„± ë° ë°˜í™˜
    return Response(generate_analysis_data(article_title_from_client, news_text_from_client), mimetype='text/event-stream')

# --- ğŸš€ ì„œë²„ ì‹¤í–‰ ---
if __name__ == '__main__':
    # 0.0.0.0ìœ¼ë¡œ í˜¸ìŠ¤íŠ¸ë¥¼ ì„¤ì •í•˜ë©´ ì™¸ë¶€ì—ì„œë„ ì ‘ì† ê°€ëŠ¥
    app.run(host='0.0.0.0', port=5000, debug=True) # ë©”ì¸ ì•±ì€ 5000ë²ˆ í¬íŠ¸ ì‚¬ìš©